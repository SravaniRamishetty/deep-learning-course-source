{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# unit 0.0 - What is machine learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose you want to find an equation for a problem\n",
        "\n",
        "PROBLEM 1 - time for an object to fall from a table 1m tall\n",
        "\n",
        "\n",
        "![](images/mofall.jpg)\n",
        "\n",
        "\n",
        "Here there is an equation and we can use it!\n",
        "\n",
        "The interesting thing is - how was this equation discovered?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PROBLEM 2 - is this a picture of a cat?\n",
        "\n",
        "![](images/cat.jpg)\n",
        "\n",
        "In this case, there is no equation...\n",
        "\n",
        "But why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CIFAR 10 dataset\n",
        "\n",
        "![](images/cifar10.png)\n",
        "\n",
        "This is another example of small images and the variety that they can have in the data / pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TRY TO USE BARD:\n",
        "\n",
        "\"can you write code to train a lenet5 in PyTorch on the cifar10 dataset?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not int",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/euge/Teaching & Projects/new Deep Learning/Deep_Learning_lecture_0-ML.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/euge/Teaching%20%26%20Projects/new%20Deep%20Learning/Deep_Learning_lecture_0-ML.ipynb#X11sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/euge/Teaching%20%26%20Projects/new%20Deep%20Learning/Deep_Learning_lecture_0-ML.ipynb#X11sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Compute the loss\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/euge/Teaching%20%26%20Projects/new%20Deep%20Learning/Deep_Learning_lecture_0-ML.ipynb#X11sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/euge/Teaching%20%26%20Projects/new%20Deep%20Learning/Deep_Learning_lecture_0-ML.ipynb#X11sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/euge/Teaching%20%26%20Projects/new%20Deep%20Learning/Deep_Learning_lecture_0-ML.ipynb#X11sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
            "\u001b[0;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not int"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        # Pooling layers\n",
        "        self.pool1 = nn.AvgPool2d(2)\n",
        "        self.pool2 = nn.AvgPool2d(2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Create the LeNet-5 model\n",
        "model = LeNet5()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(10):\n",
        "    # Train the model on the training dataset\n",
        "    for i, (data, labels) in enumerate(train_dataset):\n",
        "        # Forward pass\n",
        "        outputs = model(data)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print the progress\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.6f}'.format(epoch + 1, 10, i + 1, len(train_dataset), loss.item()))\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data, labels in test_dataset:\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the test images: {} %'.format(100 * correct / total))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It does not work and we do not know why, but it is quite close to being correct!\n",
        "\n",
        "In this course we will learn how to code this properly, or fix this properly!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
